list.files(path, all.files = TRUE)
---------------------
path = "\\\\PKX2jobs01v\\Logs\\platform\\Cake\\Task"
path = "\\\\PKX2jobs01v\\Logs\\platform\\Cake\\Task"
out.file<-""
file.names <- dir(path, pattern =".txt")
myDF <- read.fwf(file.choose(), widths = c(1100))
tmpBool1 <- str_detect(myDF$V1, "2017")
myDF <- as.data.frame(myDF[tmpBool1,])
colnames(myDF) <- c("logString")
myDF$logString <- as.character(myDF$logString)
myDF <- mutate(myDF, logDate=substr(myDF$logString, 1, 10))
myDF <- mutate(myDF, logTime=substr(myDF$logString, 11, 19))
myDF <- mutate(myDF, logTime2=substr(myDF$logString, 21, 24))
tmpPT1 <- as.data.frame(str_locate(myDF$logString, "\\]"))
tmpPT1 <- as.data.frame(tmpPT1[,1] +1)
colnames(tmpPT1) <- c("Point1")
tmpPT2 <- as.data.frame(tmpPT1[,1] + 5)
colnames(tmpPT2) <- c("Point2")
myDF <- mutate(myDF, Status=str_trim(str_sub(myDF$logString, tmpPT1$Point1, tmpPT2$Point2)))
tmpL <- str_length(myDF$logString)#9 from the end is the end of the string to ignore -(null)
tmpPT3 <- as.data.frame(tmpPT1[,1] + 7)#This is the beginning of the string detail description
colnames(tmpPT3) <- c("Point3")
myDF <- mutate(myDF, First20=str_trim(str_sub(myDF$logString, tmpPT3$Point3, tmpPT3$Point3+20)))
myDF <- mutate(myDF, Detail=str_trim(str_sub(myDF$logString, tmpPT3$Point3, tmpL-9)))
myDF <- myDF[c("logDate", "logTime", "logTime2", "Status", "First20", "Detail")]
View(myDF)
file.names[[1]]
path = "\\\\PKX2jobs01v\\Logs\\platform\\Cake\\Task"
out.file<-""
fileNames <- dir(path, pattern =".txt")
file <- paste(path, fileNames[[1]])
file
file <- paste0(path, "\\", fileNames[[1]])
file
myDF <- read.fwf(file.choose(), widths = c(2100))
myDF <- read.fwf(file, widths = c(2100))
View(myDF)
tmpBool1 <- str_detect(myDF$V1, "2017")
myDF <- as.data.frame(myDF[tmpBool1,])
colnames(myDF) <- c("logString")
myDF$logString <- as.character(myDF$logString)
myDF <- mutate(myDF, logDate=substr(myDF$logString, 1, 10))
myDF <- mutate(myDF, logTime=substr(myDF$logString, 11, 19))
myDF <- mutate(myDF, logTime2=substr(myDF$logString, 21, 24))
tmpPT1 <- as.data.frame(str_locate(myDF$logString, "\\]"))
tmpPT1 <- as.data.frame(tmpPT1[,1] +1)
colnames(tmpPT1) <- c("Point1")
tmpPT2 <- as.data.frame(tmpPT1[,1] + 5)
colnames(tmpPT2) <- c("Point2")
myDF <- mutate(myDF, Status=str_trim(str_sub(myDF$logString, tmpPT1$Point1, tmpPT2$Point2)))
tmpL <- str_length(myDF$logString)#9 from the end is the end of the string to ignore -(null)
tmpPT3 <- as.data.frame(tmpPT1[,1] + 7)#This is the beginning of the string detail description
colnames(tmpPT3) <- c("Point3")
myDF <- mutate(myDF, First20=str_trim(str_sub(myDF$logString, tmpPT3$Point3, tmpPT3$Point3+20)))
myDF <- mutate(myDF, Detail=str_trim(str_sub(myDF$logString, tmpPT3$Point3, tmpL-9)))
myDF <- myDF[c("logDate", "logTime", "logTime2", "Status", "First20", "Detail", "logString")]
myDF[123,1]
myDF[122,7]
myDF[123,7]
myDF[119,7]
library(dplyr)
library(stringr)
myDF <- read.fwf(file.choose(), widths = c(3100))
View(myDF)
myDF <- read.fwf(file.choose(), widths = c(3100), col.names = "logString", blank.lines.skip=TRUE)
-------------------------------------------------------------------
tmpBool1 <- str_detect(myDF$V1, "2017")
-------------------------------------------------------------------
tmpBool1 <- str_detect(myDF$logString, "2017")
View(myDF)
-------------------------------------------------------------------
tmpBool1 <- str_detect(myDF$logString, "2017")
tmpBool1 <- str_detect(myDF$logString, "2017")
myDF <- read.fwf(file.choose(), widths = c(3100), col.names = "logString", blank.lines.skip=TRUE)
library(stringr)
-------------------------------------------------------------------
tmpBool1 <- str_detect(myDF$logString, "2017")
str_detect(myDF$logString, "2017")
-------------------------------------------------------------------
tmpBool <- str_detect(myDF$logString, "2017")
tmpBool <- str_detect(myDF$logString, "2017")
myDF <- as.data.frame(myDF[tmpBool,])
colnames(myDF) <- c("logString")
str_detect(myDF$logString, !"2017")
str_detect(myDF$logString, "2017")
myDF[132]
myDF[132,1]
str_detect(myDF$logString, "result")
!str_detect(myDF$logString, "result")
tmpBool2 <- !str_detect(myDF$logString, "result")#remove "</result>] to data [http://ck.lendingtree" that was left from previous str_detect
myDF <- as.data.frame(myDF[tmpBool2,])
tmpBool3 <- !str_detect(myDF$logString, "string xmlns")
tmpBool3
colnames(myDF) <- c("logString")
tmpBool3 <- str_detect(myDF$logString, "string xmlns")
tmpBool3
myDF <- as.data.frame(myDF[tmpBool3,])
myDF <- read.fwf(file.choose(), widths = c(3100), col.names = "logString", blank.lines.skip=TRUE)
tmpBool <- str_detect(myDF$logString, "2017")
myDF <- as.data.frame(myDF[tmpBool,])
colnames(myDF) <- c("logString")
tmpBool2 <- !str_detect(myDF$logString, "result")#remove "</result>] to data [http://ck.lendingtree" that was left from previous str_detect
myDF <- as.data.frame(myDF[tmpBool2,])
colnames(myDF) <- c("logString")
tmpBool3 <- !str_detect(myDF$logString, "string xmlns")#remoce "<string xmlns="http://cakemarketing.com/api/" that is left over
myDF <- as.data.frame(myDF[tmpBool3,])
myDF$logString <- as.character(myDF$logString)
colnames(myDF) <- c("logString")
myDF$logString <- as.character(myDF$logString)
myDF <- mutate(myDF, logDate=substr(myDF$logString, 1, 10))
myDF <- mutate(myDF, logTime=substr(myDF$logString, 11, 19))
myDF <- mutate(myDF, logTime2=substr(myDF$logString, 21, 24))
tmpPT1 <- as.data.frame(str_locate(myDF$logString, "\\]"))
tmpPT1 <- as.data.frame(tmpPT1[,1] +1)
colnames(tmpPT1) <- c("Point1")
tmpPT2 <- as.data.frame(tmpPT1[,1] + 5)
colnames(tmpPT2) <- c("Point2")
myDF <- mutate(myDF, Status=str_trim(str_sub(myDF$logString, tmpPT1$Point1, tmpPT2$Point2)))
tmpL <- str_length(myDF$logString)#9 from the end is the end of the string to ignore -(null)
tmpPT3 <- as.data.frame(tmpPT1[,1] + 7)#This is the beginning of the string detail description
colnames(tmpPT3) <- c("Point3")
myDF <- mutate(myDF, First20=str_trim(str_sub(myDF$logString, tmpPT3$Point3, tmpPT3$Point3+20)))
myDF <- mutate(myDF, Detail=str_trim(str_sub(myDF$logString, tmpPT3$Point3, tmpL-9)))
myDF <- myDF[c("logDate", "logTime", "logTime2", "Status", "First20", "Detail", "logString")]
myDF <- filter(myDF, State != "INFO")
myDF <- filter(myDF, Status != "INFO")
install.packages("C:/Users/cweaver/Desktop/startingDataScience_0.1.1.zip", repos = NULL, type = "win.binary")
library(startingDataScience)
library(startingDataScience)
head(diamonds)
names(diamonds)
dim(diamonds)
head(economics)
head(pressure)
head(diamonds)
levels(diamonds$cut)
ggplot(data = diamonds, aes(x = cut)) +  geom_bar(stat = "count")
ggplot(data = diamonds, aes(x = cut)) +  geom_bar()
diamonds %>% group_by(cut) %>% summarise(mean(price))
df.meanPrice_by_cut <- diamonds %>% group_by(cut) %>% summarize(meanPrice = mean(price))
head(df.meanPrice_by_cut)
ggplot(data = df.meanPrice_by_cut, aes(x = cut, y = meanPrice)) +  geom_bar(stat = "identity")
ggplot(data = diamonds, aes(x = cut, y = price)) + geom_boxplot()
ggplot(data = diamonds, aes(x = cut, y = price)) +  geom_violin()
library(startingDataScience)
ggplot(data = diamonds, aes(x = carat, y = price)) + geom_point()
ggplot(data = diamonds, aes(x = carat)) + geom_histogram(fill = "dark red")
ggplot(data = diamonds, aes(x = carat, y = price)) + geom_point( aes(color = clarity ) )
foo <- rnorm( n = 15, mean = 5, sd = 2)
bar <- foo + rnorm(n = 15, mean = 5, sd =4)
size_var <- runif(15, 1,10)
bubble_data <- data.frame(foo, bar, size_var)
ggplot(data = bubble_data, aes(x = foo, y = bar)) + geom_point(aes(size = size_var))
ggplot(data = supercars, aes(x = horsepower_bhp, y = top_speed_mph)) + geom_point(aes(size = car_weight_tons))
ggplot(data = diamonds, aes(x = carat, y = price)) + geom_point(alpha = .05, color = "dark red")
d <- read.table('./data/crx.data.txt', header = FALSE, sep = ',', stringsAsFactors = FALSE, na.strings = '?')
View(d)
outcome <- 'V16'
positive <- '+'
View(d)
d[[outcome]] <- as.factor(d[[outcome]])
View(d)
?setdiff
vars <- setdiff(colnames(d), outcome)
vars
set.seed(25325)
isTrain <- runif(nrow(d)) <= 0.8
dTrain <- d[isTrain, , drop = FALSE]
dTest <- d[!isTrain, , drop = FALSE]
rm(list = 'd')
?ranger
library("ranger")
?ranger
f <- paste(outcome, paste(vars, collapse = ' + '), sep = ' ~ ')
model <- ranger(as.formula(f), probability = TRUE, data = dTrain)
d <- read.table('./data/crx.data.txt', header = FALSE, sep = ',', stringsAsFactors = FALSE, na.strings = '?')
View(d)
outcome <- 'V16'
positive <- '+'
str(d)
d[[outcome]] <- as.factor(d[[outcome]])
str(d)
vars <- setdiff(colnames(d), outcome)
vars
isTrain <- runif(nrow(d)) <= 0.8
head(isTrain)
?runif
dTrain <- d[isTrain, , drop = FALSE]
?drop
dtrain2 <- d[isTrain]
dtrain2 <- d[isTrain, ]
identical(dTrain, dtrain2)
dTest <- d[!isTrain, ]
library("ranger")# Ranger is a fast implementation of Random Forestor recursive partitioning, particularly suited for high dimensional data.
f <- paste(outcome, paste(vars, collapse = ' + '), sep = ' ~ ')
f
model <- ranger(as.formula(f), probability = TRUE, data = dTrain)
library("vtreat")
?mkCrossFrameCExperiment
cfe <- vtreat::mkCrossFrameCExperiment(dframe=dTrain, varlist=vars,
outcomename=outcome, outcometarget=positive)
plan <- cfe$treatments
plan
sf <- plan$scoreFrame
View(sf)
treatedTrain <- cfe$crossFrame
newVars <- sf$varName[sf$sig<1/nrow(sf)]
f <- paste(outcome, paste(newVars, collapse = ' + '), sep = ' ~ ')
model <- ranger(as.formula(f), probability = TRUE, data = treatedTrain)
treatedTest <- vtreat::prepare(plan, dTest, pruneSig = NULL, varRestriction = newVars)
pred <- predict(model, data=treatedTest, type='response')
treatedTest$pred <- pred$predictions[,positive]
library("WVPlots")
WVPlots::ROCPlot(treatedTest, 'pred', outcome, positive, 'test performance')
sf$take <- sf$varName %in% newVars
head(sf[, c('varName', 'rsq', 'sig', 'origName', 'code', 'take')])
library(dplyr)
available.packages() %>% tbl_df()
available.packages() %>% data.frame()
library(readr)
librdplyr
library(dplyr)
tmpDF <- read_csv(file.choose(), col_names = TRUE)
View(tmpDF)
library(readr)
tmpDF <- read_csv(file.choose(), col_names = TRUE)
hrad(tmpDF)
head(tmpDF)
head(tmpDF, 10)
library(readr)
library(tidyverse)
tmpDF <- read_csv(file.choose(), col_names = TRUE)
View(tmpDF)
library(vtreat)
d <- read.table('./data/crx.data.txt', header = FALSE, sep = ',', stringsAsFactors = FALSE, na.strings = '?')
View(d)
outcome <- 'V16'
positive <- '+'
class(d$V16)
d[[outcome]] <- as.factor(d[[outcome]])#makes character into factor
class(d$V16)
vars <- setdiff(colnames(d), outcome)
class(vars)
runif(nrow(d))
isTrain <- runif(nrow(d)) <= 0.8
dTrain <- d[isTrain, ]
dTest <- d[!isTrain, ]
rm(list = 'd')
library("ranger")# Ranger is a fast implementation of Random Forestor recursive partitioning, particularly suited for high dimensional data.
f <- paste(outcome, paste(vars, collapse = ' + '), sep = ' ~ ')
model <- ranger(as.formula(f), probability = TRUE, data = dTrain)
library("vtreat")
cfe <- vtreat::mkCrossFrameCExperiment(dframe=dTrain, varlist=vars,
outcomename=outcome, outcometarget=positive)
plan <- cfe$treatments
sf <- plan$scoreFrame
treatedTrain <- cfe$crossFrame
View(treatedTrain)
newVars <- sf$varName[sf$sig<1/nrow(sf)]
f <- paste(outcome, paste(newVars, collapse = ' + '), sep = ' ~ ')
f
model <- ranger(as.formula(f), probability = TRUE, data = treatedTrain)
treatedTest <- vtreat::prepare(plan, dTest, pruneSig = NULL, varRestriction = newVars)
pred <- predict(model, data=treatedTest, type='response')
treatedTest$pred <- pred$predictions[,positive]
library("WVPlots")
WVPlots::ROCPlot(treatedTest, 'pred', outcome, positive, 'test performance')
d <- read_csv(file.chose(), col_names = TRUE)
d <- read_csv(file.choose(), col_names = TRUE)
outcome <- "Closed"
positive <- 1
class(d$Closed)
d$Closed <- as.factor(d$Closed)
class(d$Closed)
vars <- setdiff(colnames(d), outcome)
isTrain <- runif(nrow(d)) <= .8
dTrain <- d[isTrain,]
dTest <- d[!isTrain,]
rm(list="d")
cfe <- vtreat::mkCrossFrameCExperiment(dframe=dTrain, varlist=vars,
outcomename=outcome, outcometarget=positive)
plan <- cfe$treatments
sf <- plan$scoreFrame
treatedTrain <- cfe$crossFrame
newVars <- sf$varName[sf$sig<1/nrow(sf)]
f <- paste(outcome, paste(newVars, collapse = ' + '), sep = ' ~ ')
model <- ranger(as.formula(f), probability = TRUE, data = treatedTrain)
treatedTest <- vtreat::prepare(plan, dTest, pruneSig = NULL, varRestriction = newVars)
pred <- predict(model, data=treatedTest, type='response')
treatedTest$pred <- pred$predictions[,positive]
library("WVPlots")
WVPlots::ROCPlot(treatedTest, 'pred', outcome, positive, 'test performance')
setwd("~/GitHub/Coursera_DataScientist/Machine_Learning")
#http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/
bc_data <- read.table("./data/breast-cancer-wisconsin.txt", header = FALSE, sep = ",")
colnames(bc_data) <- c("sample_code_number",
"clump_thickness",
"uniformity_of_cell_size",
"uniformity_of_cell_shape",
"marginal_adhesion",
"single_epithelial_cell_size",
"bare_nuclei",
"bland_chromatin",
"normal_nucleoli",
"mitosis",
"classes")
bc_data$classes <- ifelse(bc_data$classes == "2", "benign",ifelse(bc_data$classes == "4", "malignant", NA))
library(caret)
library(randomForest)
library(ROSE)
library(dplyr)
library(tidyr)
summary(bc_data$classes)
set.seed(42)
index <- createDataPartition(bc_data$classes, p = 0.7, list = FALSE)
train_data <- bc_data[index, ]
test_data  <- bc_data[-index, ]
model_rf <- caret::train(classes ~ ., data = train_data, method = "rf", preProcess = c("scale", "center"),
trControl = trainControl(method = "repeatedcv", number = 10, repeats = 10, verboseIter = FALSE))
final <- data.frame(actual = test_data$classes, predict(model_rf, newdata = test_data, type = "prob"))
final$predict <- ifelse(final$benign > 0.5, "benign", "malignant")
cm_original <- confusionMatrix(final$predict, test_data$classes)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10, verboseIter = FALSE, sampling = "down")
model_rf_under <- caret::train(classes ~ ., data = train_data, method = "rf", preProcess = c("scale", "center"), trControl = ctrl)
final_under <- data.frame(actual = test_data$classes, predict(model_rf_under, newdata = test_data, type = "prob"))
final_under$predict <- ifelse(final_under$benign > 0.5, "benign", "malignant")
cm_under <- confusionMatrix(final_under$predict, test_data$classes)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10, verboseIter = FALSE, sampling = "up")
model_rf_over <- caret::train(classes ~ ., data = train_data, method = "rf", preProcess = c("scale", "center"), trControl = ctrl)
final_over <- data.frame(actual = test_data$classes, predict(model_rf_over, newdata = test_data, type = "prob"))
final_over$predict <- ifelse(final_over$benign > 0.5, "benign", "malignant")
cm_over <- confusionMatrix(final_over$predict, test_data$classes)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10, verboseIter = FALSE, sampling = "rose")
model_rf_rose <- caret::train(classes ~ ., data = train_data, method = "rf", preProcess = c("scale", "center"), trControl = ctrl)
final_rose <- data.frame(actual = test_data$classes, predict(model_rf_rose, newdata = test_data, type = "prob"))
final_rose$predict <- ifelse(final_rose$benign > 0.5, "benign", "malignant")
cm_rose <- confusionMatrix(final_rose$predict, test_data$classes)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10, verboseIter = FALSE, sampling = "smote")
model_rf_smote <- caret::train(classes ~ ., data = train_data, method = "rf", preProcess = c("scale", "center"), trControl = ctrl)
final_smote <- data.frame(actual = test_data$classes, predict(model_rf_smote, newdata = test_data, type = "prob"))
final_smote$predict <- ifelse(final_smote$benign > 0.5, "benign", "malignant")
cm_smote <- confusionMatrix(final_smote$predict, test_data$classes)
models <- list(original = model_rf, under = model_rf_under, over = model_rf_over, smote = model_rf_smote, rose = model_rf_rose)
resampling <- resamples(models)
bwplot(resampling)
comparison <- data.frame(model = names(models), Sensitivity = rep(NA, length(models)), Specificity = rep(NA, length(models)),
Precision = rep(NA, length(models)), Recall = rep(NA, length(models)), F1 = rep(NA, length(models)))
for (name in names(models)) {
model <- get(paste0("cm_", name))
comparison[comparison$model == name, ] <- filter(comparison, model == name) %>%
mutate(Sensitivity = model$byClass["Sensitivity"], Specificity = model$byClass["Specificity"],
Precision = model$byClass["Precision"], Recall = model$byClass["Recall"],
F1 = model$byClass["F1"])
}
comparison %>% gather(x, y, Sensitivity:F1) %>% ggplot(aes(x = x, y = y, color = model)) +
geom_jitter(width = 0.2, alpha = 0.5, size = 3)
library(readr)
tmpData <- read_csv(file.choose())
head(tmpData)
library(dplyr)
vars <- distinct(tmpData$ProductCategory)
vars <- unique(tmpData$ProductCategory)
vars
library(readr)
tmpData <- read_csv(file.choose())
names(tmpData)
unique(QFormGroup)
unique(tmpData$QFormGroup)
set.seed(10)
y<-c(1:1000)
x1<-c(1:1000)*runif(1000,min=0,max=2)
x2<-c(1:1000)*runif(1000,min=0,max=2)
x3<-c(1:1000)*runif(1000,min=0,max=2)
lm_fit<-lm(y~x1+x2+x3)
summary(lm_fit)
set.seed(10)
all_data<-data.frame(y,x1,x2,x3)
positions <- sample(nrow(all_data),size=floor((nrow(all_data)/4)*3))
training<- all_data[positions,]
testing<- all_data[-positions,]
lm_fit<-lm(y~x1+x2+x3,data=training)
predictions<-predict(lm_fit,newdata=testing)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
library(foreach)
length_divisor<-4
iterations<-1000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
bagging<-function(training,testing,length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
rowMeans(predictions)
}
rowMeans(predictions)
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"
col.names <- c(
'Status of existing checking account', 'Duration in month', 'Credit history'
, 'Purpose', 'Credit amount', 'Savings account/bonds'
, 'Employment years', 'Installment rate in percentage of disposable income'
, 'Personal status and sex', 'Other debtors / guarantors', 'Present residence since'
, 'Property', 'Age in years', 'Other installment plans', 'Housing', 'Number of existing credits at this bank'
, 'Job', 'Number of people being liable to provide maintenance for', 'Telephone', 'Foreign worker', 'Status'
)
# Get the data
data <- read.csv(
url
, header=FALSE
, sep=' '
, col.names=col.names
)
library(rpart)
# Build a tree
# I already figured these significant variables from my first iteration (not shown in this code for simplicity)
decision.tree <- rpart(
Status ~ Status.of.existing.checking.account + Duration.in.month + Credit.history + Savings.account.bonds
, method="class"
, data=data
)
install.packages("rpart.plot")
library(rpart.plot)
# Visualize the tree
# 1 is good, 2 is bad
prp(
decision.tree
, extra=1
, varlen=0
, faclen=0
, main="Decision Tree for German Credit Data"
)
library(plumber)
install.packages("plumber")
getwd()
setwd("~/GitHub/UsingR")
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/german.data"
col.names <- c(
'Status of existing checking account', 'Duration in month', 'Credit history'
, 'Purpose', 'Credit amount', 'Savings account/bonds'
, 'Employment years', 'Installment rate in percentage of disposable income'
, 'Personal status and sex', 'Other debtors / guarantors', 'Present residence since'
, 'Property', 'Age in years', 'Other installment plans', 'Housing', 'Number of existing credits at this bank'
, 'Job', 'Number of people being liable to provide maintenance for', 'Telephone', 'Foreign worker', 'Status'
)
# Get the data
data <- read.csv(
url
, header=FALSE
, sep=' '
, col.names=col.names
)
library(rpart)
# Build a tree
# I already figured these significant variables from my first iteration (not shown in this code for simplicity)
decision.tree <- rpart(
Status ~ Status.of.existing.checking.account + Duration.in.month + Credit.history + Savings.account.bonds
, method="class"
, data=data
)
#install.packages("rpart.plot")
library(rpart.plot)
# Visualize the tree
# 1 is good, 2 is bad
prp(
decision.tree
, extra=1
, varlen=0
, faclen=0
, main="Decision Tree for German Credit Data"
)
new.data <- list(
Status.of.existing.checking.account='A11'
, Duration.in.month=20
, Credit.history='A32'
, Savings.account.bonds='A65'
)
predict(decision.tree, new.data)
save(decision.tree, file='decision_Tree_for_german_credit_data.RData')
library(rpart)
library(jsonlite)
load("decision_Tree_for_german_credit_data.RData")
#* @post /predict
predict.default.rate <- function(
Status.of.existing.checking.account
, Duration.in.month
, Credit.history
, Savings.account.bonds
) {
data <- list(
Status.of.existing.checking.account=Status.of.existing.checking.account
, Duration.in.month=Duration.in.month
, Credit.history=Credit.history
, Savings.account.bonds=Savings.account.bonds
)
prediction <- predict(decision.tree, data)
return(list(default.probability=unbox(prediction[1, 2])))
}
library(plumber)
r <- plumb("deploy_ml_credit_model.R")
r$run(port=8000)
